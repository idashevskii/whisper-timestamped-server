services:
  server:
    build:
      context: ./
      network: host
    restart: always
    ports:
      - 9001:3000
    volumes:
      - ./models/whisper:/root/.cache/whisper/
      - ./models/torch:/root/.cache/torch/
    environment:
      - WHISPER_MODEL=$WHISPER_MODEL
    logging:
      options:
        max-size: "256k"
        max-file: "1"
      driver: json-file
